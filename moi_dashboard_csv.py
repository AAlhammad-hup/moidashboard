import streamlit as st
import pandas as pd
from deep_translator import GoogleTranslator
from transformers import pipeline

# ----------------------------
# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
# ----------------------------
@st.cache_data
def load_data():
    return pd.read_csv("moi_sentiment_data.csv")

df = load_data()

# ----------------------------
# Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù„ØºØ©
# ----------------------------
language = st.sidebar.selectbox("ğŸŒ Ø§Ø®ØªØ± Ø§Ù„Ù„ØºØ© | Select Language", ["Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©", "English"])
is_arabic = language == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"

# ----------------------------
# ØªØ±Ø¬Ù…Ø§Øª Ø§Ù„Ù‚Ø·Ø§Ø¹Ø§Øª
# ----------------------------
sector_translation = {
    "Ø§Ù„Ø¯ÙØ§Ø¹ Ø§Ù„Ù…Ø¯Ù†ÙŠ": "Civil Defense",
    "Ø§Ù„Ø£Ù…Ù† Ø§Ù„Ø¹Ø§Ù…": "Public Security",
    "Ø§Ù„Ø¬ÙˆØ§Ø²Ø§Øª": "Passports",
    "Ø§Ù„Ù…Ø±ÙˆØ±": "Traffic",
    "Ø§Ù„Ø³Ø¬ÙˆÙ†": "Prisons",
    "Ù…ÙƒØ§ÙØ­Ø© Ø§Ù„Ù…Ø®Ø¯Ø±Ø§Øª": "Narcotics Control",
    "Ø­Ø±Ø³ Ø§Ù„Ø­Ø¯ÙˆØ¯": "Border Guards",
    "Ø§Ù„Ø£Ø­ÙˆØ§Ù„ Ø§Ù„Ù…Ø¯Ù†ÙŠØ©": "Civil Affairs",
    "Ø§Ù„Ø£Ù…Ù† Ø§Ù„Ø¨ÙŠØ¦ÙŠ": "Environmental Security",
    "Ù‚ÙˆØ§Øª Ø£Ù…Ù† Ø§Ù„Ù…Ù†Ø´Ø¢Øª": "Facilities Security Forces",
    "Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø·Ø¨ÙŠØ©": "Medical Services",
    "Ø£Ù†Ø¯ÙŠØ© Ø§Ù„ÙˆØ²Ø§Ø±Ø©": "Ministry Clubs Administration",
    "Ø§Ù„Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¹Ø§Ù…Ø© Ù„Ù„Ù…Ø¬Ø§Ù‡Ø¯ÙŠÙ†": "Mujahideen Administration",
    "ÙƒÙ„ÙŠØ© Ø§Ù„Ù…Ù„Ùƒ ÙÙ‡Ø¯ Ø§Ù„Ø£Ù…Ù†ÙŠØ©": "King Fahd Security College",
    "Ù‚ÙˆØ§Øª Ø§Ù„Ø£Ù…Ù† Ø§Ù„Ø®Ø§ØµØ©": "Security Protection Forces",
    "Ù…Ø±ÙƒØ² Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…ÙˆØ­Ø¯Ø©": "Unified Operations Center",
    "Ù…Ø±ÙƒØ² Ø£Ø¨Ø­Ø§Ø« Ø§Ù„Ø¬Ø±ÙŠÙ…Ø©": "Crime Research Center",
    "Ø¯ÙŠÙˆØ§Ù† Ø§Ù„ÙˆØ²Ø§Ø±Ø©": "MOI Diwan",
    "Ù…Ø±ÙƒØ² Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ÙˆØ·Ù†ÙŠ": "National Information Center"
}
sector_translation_rev = {v: k for k, v in sector_translation.items()}

# ----------------------------
# ØªØ±Ø¬Ù…Ø§Øª Ø§Ù„Ù…Ø´Ø§Ø¹Ø±
# ----------------------------
sentiment_translation = {
    "Positive": "Ø¥ÙŠØ¬Ø§Ø¨ÙŠ",
    "Negative": "Ø³Ù„Ø¨ÙŠ",
    "Neutral": "Ù…Ø­Ø§ÙŠØ¯"
}
sentiment_translation_rev = {v: k for k, v in sentiment_translation.items()}

# ----------------------------
# Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ù„ÙˆØ­Ø©
# ----------------------------
st.title("Ù„ÙˆØ­Ø© Ø§Ù„Ø±ØµØ¯ Ø§Ù„Ø£Ù…Ù†ÙŠ" if is_arabic else "Security Sentiment Dashboard")
st.markdown("ØªØ­Ù„ÙŠÙ„ Ø±Ø£ÙŠ Ø§Ù„Ø¬Ù…Ù‡ÙˆØ± Ø­ÙˆÙ„ Ø®Ø¯Ù…Ø§Øª ÙˆØ²Ø§Ø±Ø© Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ©" if is_arabic else "Analyzing public opinion on Ministry of Interior services")

# ----------------------------
# Ø§Ù„Ù‚Ø·Ø§Ø¹Ø§Øª
# ----------------------------
available_ar_sectors = sorted(df["Sector"].unique())
available_en_sectors = [sector_translation.get(sec, sec) for sec in available_ar_sectors]

selected_sector_display = st.selectbox(
    "Ø§Ø®ØªØ± Ø§Ù„Ù‚Ø·Ø§Ø¹ Ø§Ù„Ø£Ù…Ù†ÙŠ" if is_arabic else "Select Security Sector",
    available_ar_sectors if is_arabic else available_en_sectors
)

selected_arabic_sector = selected_sector_display if is_arabic else sector_translation_rev.get(selected_sector_display, selected_sector_display)
filtered_df = df[df["Sector"] == selected_arabic_sector].copy()

# ----------------------------
# Ø§Ù„ØªØ±Ø¬Ù…Ø© Ø§Ù„ÙØ¹Ù„ÙŠØ©
# ----------------------------
def translate_text(text, target="en"):
    try:
        return GoogleTranslator(source='auto', target=target).translate(text)
    except:
        return text  # fallback

# ----------------------------
# Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
# ----------------------------
if is_arabic:
    filtered_df["Ø§Ù„Ø±Ø£ÙŠ"] = filtered_df["Sentiment"].map(sentiment_translation).fillna("ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ")
    filtered_df["Ø§Ù„Ù†Øµ"] = filtered_df["Text"]
    display_df = filtered_df[["Ø§Ù„Ù†Øµ", "Ø§Ù„Ø±Ø£ÙŠ"]]
    chart_data = filtered_df["Ø§Ù„Ø±Ø£ÙŠ"].value_counts()
    st.subheader("Ø§Ù„Ù†ØªØ§Ø¦Ø¬")
    st.write(display_df)
    st.subheader("Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ø§Ù…")
    st.bar_chart(chart_data)
else:
    filtered_df["Translated"] = filtered_df["Text"].apply(lambda x: translate_text(x, "en"))
    display_df = filtered_df[["Translated", "Sentiment"]].rename(columns={"Translated": "Comment"})
    chart_data = filtered_df["Sentiment"].value_counts()
    st.subheader("Results")
    st.write(display_df)
    st.subheader("Overall Sentiment Analysis")
    st.bar_chart(chart_data)

# ----------------------------
# ØªÙ„Ø®ÙŠØµ Ø§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… LLM
# ----------------------------
@st.cache_resource
def load_summarizer():
    return pipeline("summarization", model="facebook/bart-large-cnn")

summarizer = load_summarizer()

def generate_summary(texts, max_chars=2000):
    # Ø¯Ù…Ø¬ Ø§Ù„Ù†ØµÙˆØµ ÙÙŠ Ù†Øµ ÙˆØ§Ø­Ø¯ (Ù…Ø¹ Ù‚Øµ Ø§Ù„Ø·ÙˆÙ„ Ø¥Ø°Ø§ Ø²Ø§Ø¯ Ø¹Ù† Ø§Ù„Ø­Ø¯)
    combined = " ".join(texts)
    combined = combined[:max_chars]
    try:
        summary = summarizer(combined, max_length=100, min_length=30, do_sample=False)
        return summary[0]['summary_text']
    except Exception as e:
        return f"ÙØ´Ù„ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ù„Ø®Øµ: {e}"

st.subheader("Ù…Ù„Ø®Øµ Ø§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª" if is_arabic else "Review Summary")
reviews_to_summarize = filtered_df["Text"].astype(str).tolist()
summary_text = generate_summary(reviews_to_summarize)
st.write(summary_text)
