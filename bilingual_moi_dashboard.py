import streamlit as st
import snscrape.modules.twitter as sntwitter
import pandas as pd
from transformers import pipeline
from googletrans import Translator
import subprocess
import json

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ù„Ù…ØªØ±Ø¬Ù…
sentiment_model = pipeline("sentiment-analysis", model="nlptown/bert-base-multilingual-uncased-sentiment")
translator = Translator()

# Ù„ØºØ© Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©
language = st.sidebar.selectbox("ðŸŒ Ø§Ø®ØªØ± Ø§Ù„Ù„ØºØ© | Select Language", ["Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©", "English"])
is_arabic = language == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"

# Ø¹Ù†Ø§ÙˆÙŠÙ† Ø§Ù„Ù‚Ø·Ø§Ø¹Ø§Øª Ø§Ù„ØªÙŠ Ø³ÙŠØªÙ… ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØºØ±ÙŠØ¯Ø§Øª Ø¹Ù†Ù‡Ø§
MOI_SECTORS = [
    "Ø§Ù„Ø¯ÙØ§Ø¹ Ø§Ù„Ù…Ø¯Ù†ÙŠ",
    "Ø§Ù„Ù…Ø¯ÙŠØ±ÙŠØ© Ø§Ù„Ø¹Ø§Ù…Ø© Ù„Ù„Ø£Ù…Ù† Ø§Ù„Ø¹Ø§Ù…",
    "Ø§Ù„Ù…Ø¯ÙŠØ±ÙŠØ© Ø§Ù„Ø¹Ø§Ù…Ø© Ù„Ù…ÙƒØ§ÙØ­Ø© Ø§Ù„Ù…Ø®Ø¯Ø±Ø§Øª",
    "Ø§Ù„Ù…Ø¯ÙŠØ±ÙŠØ© Ø§Ù„Ø¹Ø§Ù…Ø© Ù„Ù„Ø¬ÙˆØ§Ø²Ø§Øª",
    "Ø§Ù„Ù…Ø¯ÙŠØ±ÙŠØ© Ø§Ù„Ø¹Ø§Ù…Ø© Ù„Ù„Ø³Ø¬ÙˆÙ†",
    "Ø§Ù„Ù…Ø¯ÙŠØ±ÙŠØ© Ø§Ù„Ø¹Ø§Ù…Ø© Ù„Ø­Ø±Ø³ Ø§Ù„Ø­Ø¯ÙˆØ¯",
    "Ø§Ù„Ù‚ÙˆØ§Øª Ø§Ù„Ø®Ø§ØµØ© Ù„Ù„Ø£Ù…Ù† Ø§Ù„Ø¨ÙŠØ¦ÙŠ",
    "Ø§Ù„Ù‚ÙˆØ§Øª Ø§Ù„Ø®Ø§ØµØ© Ù„Ù„Ø£Ù…Ù† ÙˆØ§Ù„Ø­Ù…Ø§ÙŠØ©",
    "ÙƒÙ„ÙŠØ© Ø§Ù„Ù…Ù„Ùƒ ÙÙ‡Ø¯ Ø§Ù„Ø£Ù…Ù†ÙŠØ©",
    "ÙˆÙƒØ§Ù„Ø© ÙˆØ²Ø§Ø±Ø© Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ© Ù„Ù„Ø£Ø­ÙˆØ§Ù„ Ø§Ù„Ù…Ø¯Ù†ÙŠØ©",
    "Ù…Ø±ÙƒØ² Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ÙˆØ·Ù†ÙŠ",
    "Ø§Ù„Ù…Ø±ÙƒØ² Ø§Ù„ÙˆØ·Ù†ÙŠ Ù„Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ø£Ù…Ù†ÙŠØ© Ø§Ù„Ù…ÙˆØ­Ø¯Ø©",
    "Ù…Ø±ÙƒØ² Ø£Ø¨Ø­Ø§Ø« Ù…ÙƒØ§ÙØ­Ø© Ø§Ù„Ø¬Ø±ÙŠÙ…Ø©",
    "Ù‚ÙˆØ§Øª Ø£Ù…Ù† Ø§Ù„Ù…Ù†Ø´Ø¢Øª",
    "Ø§Ù„Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¹Ø§Ù…Ø© Ù„Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø·Ø¨ÙŠØ©",
    "Ø§Ù„Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¹Ø§Ù…Ø© Ù„Ø£Ù†Ø¯ÙŠØ© Ù…Ù†Ø³ÙˆØ¨ÙŠ ÙˆØ²Ø§Ø±Ø© Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ©",
    "Ø§Ù„Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¹Ø§Ù…Ø© Ù„Ù„Ù…Ø¬Ø§Ù‡Ø¯ÙŠÙ†",
    "Ø¯ÙŠÙˆØ§Ù† ÙˆØ²Ø§Ø±Ø© Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ©"
]

# Ø¹Ø±Ø¶ Ø¹Ù†ÙˆØ§Ù† Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©
st.title("ðŸ“Š Ù„ÙˆØ­Ø© ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±Ø£ÙŠ Ø§Ù„Ø¹Ø§Ù… Ù„Ù‚Ø·Ø§Ø¹Ø§Øª ÙˆØ²Ø§Ø±Ø© Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ©" if is_arabic else "ðŸ“Š Public Sentiment Dashboard for MOI Sectors")

# ØªØ­Ù…ÙŠÙ„ ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØºØ±ÙŠØ¯Ø§Øª
results = []

for sector in MOI_SECTORS:
    query = f"{sector} lang:ar"
    tweets = []
    for i, tweet in enumerate(sntwitter.TwitterSearchScraper(query).get_items()):
        if i > 20:
            break
        tweets.append(tweet.content)

    for text in tweets:
        try:
            translated = translator.translate(text, dest="en").text
            sentiment = sentiment_model(translated)[0]
            results.append({
                "Ø§Ù„Ù‚Ø·Ø§Ø¹" if is_arabic else "Sector": sector,
                "Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ" if is_arabic else "Original Text": text,
                "Ø§Ù„ØªØ±Ø¬Ù…Ø©" if is_arabic else "Translation": translated,
                "Ø§Ù„Ø±Ø£ÙŠ" if is_arabic else "Sentiment": sentiment["label"],
                "Ø¯Ø±Ø¬Ø© Ø§Ù„Ø«Ù‚Ø©" if is_arabic else "Confidence": round(sentiment["score"] * 100, 2)
            })
        except Exception as e:
            continue

# Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
if results:
    df = pd.DataFrame(results)
    st.dataframe(df)
    sentiment_summary = df.groupby("Ø§Ù„Ù‚Ø·Ø§Ø¹" if is_arabic else "Sector")["Ø§Ù„Ø±Ø£ÙŠ" if is_arabic else "Sentiment"].value_counts().unstack().fillna(0)
    st.bar_chart(sentiment_summary)
else:
    st.info("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬." if is_arabic else "No results found.")
