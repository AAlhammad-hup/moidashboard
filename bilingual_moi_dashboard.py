
import streamlit as st
import snscrape.modules.twitter as sntwitter  
import pandas as pd
from transformers import pipeline
from googletrans import Translator
import subprocess
import json

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ù„Ù…ØªØ±Ø¬Ù…
sentiment_model = pipeline("sentiment-analysis", model="nlptown/bert-base-multilingual-uncased-sentiment")
translator = Translator()

# Ù„ØºØ© Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©
language = st.sidebar.selectbox("ğŸŒ Ø§Ø®ØªØ± Ø§Ù„Ù„ØºØ© | Select Language", ["Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©", "English"])
is_arabic = language == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"

# Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù‚Ø·Ø§Ø¹Ø§Øª
sectors = [
    "Ø§Ù„Ø¯ÙØ§Ø¹ Ø§Ù„Ù…Ø¯Ù†ÙŠ",
    "Ø§Ù„Ù…Ø¯ÙŠØ±ÙŠØ© Ø§Ù„Ø¹Ø§Ù…Ø© Ù„Ù„Ø£Ù…Ù† Ø§Ù„Ø¹Ø§Ù…",
    "Ø§Ù„Ù…Ø¯ÙŠØ±ÙŠØ© Ø§Ù„Ø¹Ø§Ù…Ø© Ù„Ù…ÙƒØ§ÙØ­Ø© Ø§Ù„Ù…Ø®Ø¯Ø±Ø§Øª",
    "Ø§Ù„Ù…Ø¯ÙŠØ±ÙŠØ© Ø§Ù„Ø¹Ø§Ù…Ø© Ù„Ù„Ø¬ÙˆØ§Ø²Ø§Øª",
    "Ø§Ù„Ù…Ø¯ÙŠØ±ÙŠØ© Ø§Ù„Ø¹Ø§Ù…Ø© Ù„Ù„Ø³Ø¬ÙˆÙ†",
    "Ø§Ù„Ù…Ø¯ÙŠØ±ÙŠØ© Ø§Ù„Ø¹Ø§Ù…Ø© Ù„Ø­Ø±Ø³ Ø§Ù„Ø­Ø¯ÙˆØ¯",
    "Ø§Ù„Ù‚ÙˆØ§Øª Ø§Ù„Ø®Ø§ØµØ© Ù„Ù„Ø£Ù…Ù† Ø§Ù„Ø¨ÙŠØ¦ÙŠ",
    "Ø§Ù„Ù‚ÙˆØ§Øª Ø§Ù„Ø®Ø§ØµØ© Ù„Ù„Ø£Ù…Ù† ÙˆØ§Ù„Ø­Ù…Ø§ÙŠØ©",
    "ÙƒÙ„ÙŠØ© Ø§Ù„Ù…Ù„Ùƒ ÙÙ‡Ø¯ Ø§Ù„Ø£Ù…Ù†ÙŠØ©",
    "ÙˆÙƒØ§Ù„Ø© ÙˆØ²Ø§Ø±Ø© Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ© Ù„Ù„Ø£Ø­ÙˆØ§Ù„ Ø§Ù„Ù…Ø¯Ù†ÙŠØ©",
    "Ù…Ø±ÙƒØ² Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ÙˆØ·Ù†ÙŠ",
    "Ø§Ù„Ù…Ø±ÙƒØ² Ø§Ù„ÙˆØ·Ù†ÙŠ Ù„Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ø£Ù…Ù†ÙŠØ© Ø§Ù„Ù…ÙˆØ­Ø¯Ø©",
    "Ù…Ø±ÙƒØ² Ø£Ø¨Ø­Ø§Ø« Ù…ÙƒØ§ÙØ­Ø© Ø§Ù„Ø¬Ø±ÙŠÙ…Ø©",
    "Ù‚ÙˆØ§Øª Ø£Ù…Ù† Ø§Ù„Ù…Ù†Ø´Ø¢Øª",
    "Ø§Ù„Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¹Ø§Ù…Ø© Ù„Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø·Ø¨ÙŠØ©",
    "Ø§Ù„Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¹Ø§Ù…Ø© Ù„Ø£Ù†Ø¯ÙŠØ© Ù…Ù†Ø³ÙˆØ¨ÙŠ ÙˆØ²Ø§Ø±Ø© Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ©",
    "Ø§Ù„Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¹Ø§Ù…Ø© Ù„Ù„Ù…Ø¬Ø§Ù‡Ø¯ÙŠÙ†",
    "Ø¯ÙŠÙˆØ§Ù† ÙˆØ²Ø§Ø±Ø© Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ©"
]

# ØªØ±Ø¬Ù…Ø© Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©
def _(ar, en):
    return ar if is_arabic else en

# ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±
def simplify_sentiment(label):
    if "1" in label or "2" in label:
        return _("Ø³Ù„Ø¨ÙŠ", "Negative")
    elif "4" in label or "5" in label:
        return _("Ø¥ÙŠØ¬Ø§Ø¨ÙŠ", "Positive")
    else:
        return _("Ù…Ø­Ø§ÙŠØ¯", "Neutral")

def translate_text(text):
    try:
        return translator.translate(text, dest="en").text
    except:
        return text

def analyze_sentiment(text):
    try:
        translated = translate_text(text)
        result = sentiment_model(translated)[0]["label"]
        return simplify_sentiment(result)
    except:
        return _("Ø®Ø·Ø£", "Error")

# Ø¬Ù…Ø¹ Ø¨ÙŠØ§Ù†Ø§Øª ØªÙˆÙŠØªØ±
def collect_from_twitter(query, limit):
    tweets = []
    for tweet in sntwitter.TwitterSearchScraper(query + " lang:ar").get_items():
        if len(tweets) >= limit:
            break
        tweets.append([tweet.date, tweet.user.username, tweet.content])
    return pd.DataFrame(tweets, columns=[_("Ø§Ù„ØªØ§Ø±ÙŠØ®", "Date"), _("Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…", "User"), _("Ø§Ù„Ù†Øµ", "Text")])

# Ø¬Ù…Ø¹ ØªØ¹Ù„ÙŠÙ‚Ø§Øª ÙŠÙˆØªÙŠÙˆØ¨
def collect_from_youtube(video_url, limit):
    subprocess.run([
        "youtube-comment-downloader",
        "--url", video_url,
        "--output", "comments.json",
        "--limit", str(limit)
    ], capture_output=True, text=True)
    try:
        with open("comments.json", "r", encoding="utf-8") as f:
            lines = f.readlines()
        comments = [json.loads(line)["text"] for line in lines]
        return pd.DataFrame(comments, columns=[_("Ø§Ù„Ù†Øµ", "Text")])
    except:
        return pd.DataFrame(columns=[_("Ø§Ù„Ù†Øµ", "Text")])

# ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
st.set_page_config(page_title=_("Ù„ÙˆØ­Ø© ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±Ø£ÙŠ Ø§Ù„Ø¹Ø§Ù…", "Public Sentiment Dashboard"), layout="wide")
st.title(_("ğŸ“Š Ù„ÙˆØ­Ø© ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±Ø£ÙŠ Ø§Ù„Ø¹Ø§Ù… Ù„Ù‚Ø·Ø§Ø¹Ø§Øª ÙˆØ²Ø§Ø±Ø© Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ©", "ğŸ“Š Sentiment Analysis Dashboard for MOI Sectors"))

sector = st.selectbox(_("Ø§Ø®ØªØ± Ø§Ù„Ù‚Ø·Ø§Ø¹", "Select Sector"), sectors)
platform = st.selectbox(_("Ø§Ø®ØªØ± Ø§Ù„Ù…Ù†ØµØ©", "Select Platform"), ["Twitter", "YouTube", "Google Reviews", "Telegram"])
custom_input = st.text_input(_("ğŸ” Ø£Ø¯Ø®Ù„ ÙƒÙ„Ù…Ø© Ø¨Ø­Ø« Ø£Ùˆ Ø±Ø§Ø¨Ø· ÙÙŠØ¯ÙŠÙˆ", "ğŸ” Enter search keyword or video URL"))
limit = st.slider(_("Ø¹Ø¯Ø¯ Ø§Ù„Ù†ØªØ§Ø¦Ø¬", "Number of results"), 10, 200, 50)
api_key = st.text_input("ğŸ”‘ Google API Key", type="password") if platform == "Google Reviews" else None

if st.button(_("Ø§Ø¨Ø¯Ø£ Ø§Ù„ØªØ­Ù„ÙŠÙ„", "Start Analysis")):
    query = custom_input if custom_input else sector

    if platform == "Twitter":
        st.info(_("ğŸ“¡ ÙŠØªÙ… Ø¬Ù…Ø¹ Ø§Ù„ØªØºØ±ÙŠØ¯Ø§Øª...", "Collecting tweets..."))
        df = collect_from_twitter(query, limit)
    elif platform == "YouTube":
        st.info(_("ğŸ“¡ ÙŠØªÙ… Ø¬Ù…Ø¹ ØªØ¹Ù„ÙŠÙ‚Ø§Øª ÙŠÙˆØªÙŠÙˆØ¨...", "Collecting YouTube comments..."))
        df = collect_from_youtube(query, limit)
    elif platform == "Telegram":
        st.warning(_("ğŸš§ Ø¯Ø¹Ù… ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù… Ù„Ù… ÙŠÙÙØ¹Ù„ Ø¨Ø¹Ø¯.", "ğŸš§ Telegram support not yet implemented."))
        df = pd.DataFrame(columns=[_("Ø§Ù„Ù†Øµ", "Text")])
    elif platform == "Google Reviews":
        st.warning(_("ğŸš§ Ø¯Ø¹Ù… Google Ù„Ù… ÙŠÙÙØ¹Ù„ Ø¨Ø¹Ø¯.", "ğŸš§ Google Reviews support not yet implemented."))
        df = pd.DataFrame(columns=[_("Ø§Ù„Ù†Øµ", "Text")])
    else:
        df = pd.DataFrame(columns=[_("Ø§Ù„Ù†Øµ", "Text")])

    if not df.empty:
        st.info(_("ğŸ¤– ÙŠØªÙ… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±...", "ğŸ¤– Analyzing sentiment..."))
        df[_("Ø§Ù„Ù…Ø´Ø§Ø¹Ø±", "Sentiment")] = df[_("Ø§Ù„Ù†Øµ", "Text")].apply(analyze_sentiment)

        st.subheader(_("ğŸ“ˆ ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±", "ğŸ“ˆ Sentiment Distribution"))
        st.bar_chart(df[_("Ø§Ù„Ù…Ø´Ø§Ø¹Ø±", "Sentiment")].value_counts())

        st.subheader(_("ğŸ“‹ Ø§Ù„ØªÙØ§ØµÙŠÙ„", "ğŸ“‹ Detailed Data"))
        st.dataframe(df)
    else:
        st.warning(_("âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬", "âš ï¸ No results found."))
